817*：
1. 简述数据挖掘的概念及其含义。2. 简述多路数组聚集进行立方体计算的方法。   假定一个基本方体有三个维ABC，其单元数如下|A|=1000000，|B|=100，|C|=1000，并   且分块将每维分成10部分，假设每一个维只有一层，指出立方体中空间需求量最小的   块计算顺序，并计算2-维平面所需要的内存空间的空间量。3. 现将9个人分成两组，每一组人所具有的属性和属性值如表所示，说明在这些属性中哪   一个属性对于区分这两组数据最重要？并给出分析过程(至少使用两种方法，并分析优   劣)        组次    例      身材    发色    眼睛        第一组  1       矮      金色    蓝色                2       高      红色    蓝色                3       高      金色    蓝色                4       矮      金色    灰色        第二组  1       高      黑色    黑色
                2       矮      黑色    蓝色                3       高      黑色    蓝色                4       高      黑色    灰色                5       矮      金色    黑色912*:
1.Suppose a group of 12 students with the test scores listed as follows:        19, 71, 48, 63, 35, 85, 69, 81, 72, 88, 99, 95        Partition them into four bins byequal-frequency (equi-depth) method,equal-width method, andan even better method (such as clustering).2.Table 1 shows how many transactions containing beer and/or nuts among 10000transactions(roughly) calculatecalculate liftcalculate all-confidence, andbased on your calculation, how do you conclude the relationship betweenbuying_beer and buying_nuts?        Beer    No Beer TotalNuts    50      800     850No Nuts 150     9000    9150
Total   200     9800    100003.A database with 100 transactions has its FP-tree shown in Fig. 1. Let min_sup =0.4 and min_conf = 0.6. Showc’s conditional databasethe frequent k-itemset for the largest k, andall the strong association rules (with support and confidence) containing the kitems (for the largest k only).1199*:
// 开卷，可以用本。助教说：最好不要用计算机，用的话把MSN关掉。// 第2题中，data疑为date。经询问，助教同意了这一改正。1. 什么是OLAP和OLTP？阐述他们之间的联系和区别2. 假定某一数据仓库包含4个维data, spectator, location和game，2个度量count和charge。其中charge是观众在给定的日期观看节目的费用，观众可以是学生、成年人或老人，每类观众有不同的收费标准。(1) 画出该数据仓库的星型模式图(2) 基本方体[data, spectator, location, game]开始，为列出2000年学生观众在GM-place的总付费，应当执行哪些OLAP操作。(3) 为得到同样结果，写一个SQL语句。假定数据存放在关系数据库中，Charge(day, month, year, spectator, theater_location, game, count, charge)3. 右表是对10个人申请银行贷款的记录，每个人所具有的属性和属性值如右表所示，说明对欺诈行为最重要的属性是什么？并给出分析过程。
ID      RF      MA       TSA    Cheat-------------------------------------1       Yes     Single   125K   No2       No      Married  100K   No3       No      Single   70K    No4       Yes     Married  120K   No5       No      Divorced 95K    Yes6       No      Married  60K    No7       Yes     Divorced 220K   No8       No      Single   85K    Yes9       No      Married  75K    No10      No      Single   90K    YesRF: RefundMA: Marital StatusSA: Taxable IncomeCheat: 欺诈，Y: 存在，N: 不存在

1413*:
1. 数据挖掘技术具有以下挖掘功能：概念描述和区分，关联规则挖掘，分类，   聚类，预测和演化分析等。以 World Wide Web 为挖掘对象，列举三种可使用   数据挖掘功能的 Web 应用，并给以简单描述。2. 下面是一个关于学生年龄 (age, 数值型属性) 与成绩 (Grade, 标称型属性   (P:pass, F:fail)) 的数据表。      ID     1   2   3   4   5   6   7   8   9      Age    21  22  24  25  27  27  31  35  41      Grade  F   F   P   F   P   P   P   P   P   a) 设 Grade 是一个分类属性，用信息熵方法把 age 的属性值划分为两个区      间：Young 和 Old。   b) 使用 min-max 标准化方法，把 age 中 27 转换为属于 [0.0, 1.0] 区间的值。3. 设计一个关于货运信息的数据仓库，数据仓库中包含下列信息：货运组，货   物信息，起点信息，终点信息。   a) 给出该数据仓库的星状模型 (可以自己设计维的属性和属性概念层次)
   b) 从该数据仓库的顶点方体 (apex cuboid) 出发，给出得到从北京到呼和浩      特由小红马快递在 2006 年第一季度运送电脑的总台数与运费的 OLAP 操      作。1557*:
一共三道题，其实是前4年题目的拼凑,考试时间一节课。。一.数据挖掘是什么？简述其概念和过程。二.(其实是07年第二题的前2问，估计这次课程的进度稍慢了点，所以第三小问被删掉了)假定某一数据仓库包含4个维date, spectator, location和game，2个度量count和charge。其中charge是观众在给定的日期观看节目的费用，观众可以是学生、成年人或老人，每类观众有不同的收费标准。(1) 画出该数据仓库的星型模式图(2) 基本方体[date, spectator, location, game]开始，为列出2000年学生观众在GM-place的总付费，应当执行哪些OLAP操作。三.给了一个事务表，具体的不记得了(如果待会能弄到试题纸再贴上来），就是类似下面的这样-------------------------   | B    A     C     K     |   -------------------------   |    C     B     A       |
   -------------------------   |    B   A   C  D   E    |   --------------------------   |     A    B    D   E    |   --------------------------   |    B   A    D          |   --------------------------   min_sup=2;   1.画出FP树   2.根据FP算法，写出包含E项的频繁模式   3.写出下面元规则的频繁模式      buy(x)&buy(y)-->buy(z)

1528:
期末考试：2009年1月6日，19:00 - 21:00, 延长至21:15 (还可再拖一会儿)开卷考试，可以带任何东西，包括笔记本；可以上网（老师说的）不过这次是在五教考的，电源不够 -_-b欢迎大家补充一、多项选择题，每题2分，共30分; 每题可能有多个正确答案，不过大部分都是单选1. 子集、超集，频繁方面的闭合特性2. 约束的单调、反单调能否同时存在3. 两个约束C1, C2, 一个单调，一个反单调，问什么什么转换
4. 子序列计算什么个数5. 序列挖掘，算 maximum period 和 semi-maximum period6. XML查询的UDFTS的计算7. XML查询的False Sequence判断8. 忘了9. 忘了10. Ensemble learning错误预测的计算11. Sensitivity, Specificity和False positive/negative rate的关系12. Euclidean和Manhattan距离是不是metric distance13. 忘了14. 忘了
15. 最长频繁项是不是closed的，是不是maximal的// 上面这些题几乎可以在课件里找到原话，计算型的也大都可以直接套课件上的公式二、填空，每空1分，共47分16. 数 6,2,3,6,6,8,1,5,1,2,4, 计算平均数、中位数、方差、模式（mode），调和平均，以及五数摘要(five-number summary)的5个数// 本题调和平均课件上没有；不过这些数用excel的函数全搞定17. 一些数1,1,2,2,4,4,5,6,6,7,7,7,8,9,10(原题未排序), 用equal-depth进行3个bin的binning, 之后进行smoothing by bin boundaries, 填写最终的三个bin的内容// 书和课件上都有18. 填表（yes, no）Constraint      Antimonotonic   Monotonic       Succinctv∈Ssupport(S)>=ξsupport(S)<=ξ// 英文影印第2版书P271, 表5.12 照抄
19. 感知器学习，λ=0.2, t=0.5, 初始W1=W2=0.2, 填W值X1      X2      Y       W1      W20       0       00       1       11       0       11       1       1// 课件上有个类似的，不过我不明白怎么算，挂了20. 计算下面矩阵的Manhattan距离，欧氏距离，相关(Correlation)距离，MSRS，pScore _      _|  0  1  ||_ -1 0 _|// Correlation距离不会算，其他课件/书上都有三、计算χ^2，6分        A       ~AB       5       4~B      1       20// a,b,c,d具体数忘了，反正直接算吧四、算FPTree, 7分，项比较多，不过min_sup=3, 所以扔掉好些五、Naive Bayesian classification, 6分就是书上(英文影印第2版)P313/Example 6.4, 连表都一样，只是求的改了六、4分。熵是有multistage property的，有9个实例，2个在类1，3个在类2，4个在类3。要求证明：entropy([2,3,4]) = E([2,7]) + (7/9) * entropy([3,4])

1801:
// 可以带本，且5104能上网……// 跟以前的应该一模一样吧，做完以后补充完整了……一、多项选择题，每题2分，共30分; 每题可能有多个正确答案，不过大部分都是单选1. 子集、超集，频繁方面的闭合特性   // downward closure property2. 约束的单调、反单调能否同时存在3. 两个约束C1, C2, 一个单调，一个反单调，问什么什么转换   // 约束转换应该先满足哪一个4. 子序列计算什么个数   // length-2 candidates consisting of two events5. 序列挖掘，算 maximum period 和 semi-maximum period   // 2-nd mp & smp6. XML查询的UDFTS的计算7. diffset8. information gain, gini index, overfitting, gain ratio9. svm对高维数据非常有效10. Ensemble learning错误预测的计算11. Sensitivity, Specificity和False positive/negative rate的关系12. Euclidean和Manhattan距离是不是metric distance13. k-means, k-medoids14. birch15. 最长频繁项是不是closed的，是不是maximal的二、填空，每空1分，共47分16. 数 6,2,3,6,6,8,1,5,1,2,4, 计算平均数、中位数、方差、模式（mode），调和平均，以及五数摘要(five-number summary)的5个数17. 一些数1,1,2,2,4,4,5,6,6,7,7,7,8,9,10(原题未排序), 用equal-depth进行3个bin的
binning, 之后进行smoothing by bin boundaries, 填写最终的三个bin的内容18. 填表（yes, no）Constraint      Antimonotonic   Monotonic       Succinctv∈Ssupport(S)>=ξsupport(S)<=ξ// 英文影印第2版书P271, 表5.12 照抄19. 感知器学习，λ=0.2, t=0.5, 初始W1=W2=0.2, 填W值X1      X2      Y       W1      W20       0       00       1       11       0       11       1       120. 计算下面矩阵的Manhattan距离，欧氏距离，相关(Correlation)距离，MSRS，pScore _      _|  0  1  ||_ -1 0 _|三、计算χ^2，6分        A       ~AB       5       4~B      1       20四、算FPTree, 7分，项比较多，不过min_sup=3, 所以扔掉好些五、Naive Bayesian classification, 6分就是书上(英文影印第2版)P313/Example 6.4, 连表都一样，只是求的改了// student = no, 书上是student = yes六、4分。熵是有multistage property的，有9个实例，2个在类1，3个在类2，4个在类3。要求证明：entropy([2,3,4]) = E([2,7]) + (7/9) * entropy([3,4])
